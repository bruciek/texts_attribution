{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:03:45.563228200Z",
     "start_time": "2023-07-23T13:03:44.242790700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def dataset_target(dataset):\n",
    "    authors = list(set(dataset['authors']))\n",
    "    dict_authors = dict()\n",
    "    reverse_dict_authors = dict()\n",
    "    for index in range(len(authors)):\n",
    "        dict_authors[authors[index]] = index\n",
    "        reverse_dict_authors[index] = authors[index]\n",
    "    target = []\n",
    "    for author in dataset[\"authors\"]:\n",
    "        target += [dict_authors[author]]\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:03:45.864957200Z",
     "start_time": "2023-07-23T13:03:45.856814100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from features.features_lemma_part_speech import get_feature_lemma_part_speech\n",
    "from features.features_with_word_count import get_feature_symbol\n",
    "from features.features_with_sentence_list import get_feature_sents\n",
    "from features.features_words import get_feature_word\n",
    "from features.features_bin import get_feature_bin\n",
    "from features.features_text import get_feature_text\n",
    "\n",
    "def get_list_of_features(doc):\n",
    "    features_symbol = get_feature_symbol(doc)\n",
    "    features_words = get_feature_word(doc)\n",
    "    features_sents = get_feature_sents(doc)\n",
    "    features_lemma_part_speech = get_feature_lemma_part_speech(doc)\n",
    "    features_bin = get_feature_bin(doc)\n",
    "    features_text = get_feature_text(doc)\n",
    "    list_of_features = features_sents + features_words + features_symbol + features_lemma_part_speech + features_bin + features_text\n",
    "    return list_of_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:03:46.633692600Z",
     "start_time": "2023-07-23T13:03:46.377479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from features.features_words import func_words\n",
    "from features.features_with_sentence_list import FUNC_LIST\n",
    "from features.features_with_word_count import func_chars\n",
    "from features.features_lemma_part_speech import func_lemma_part_speech\n",
    "from features.features_bin import func_bin\n",
    "from features.features_text import func_text\n",
    "\n",
    "from tqdm import tqdm\n",
    "all_func = FUNC_LIST + func_words + func_chars + func_lemma_part_speech + func_bin + func_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:04:40.590263700Z",
     "start_time": "2023-07-23T13:04:40.560552500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import compress_pickle\n",
    "import os\n",
    "\n",
    "\n",
    "observations = []\n",
    "DATA_PATH = \"C:\\\\Users\\\\user\\\\PycharmProjects\\\\texts_attribution\\\\Данные\"\n",
    "with open(os.path.join(DATA_PATH, \"docs_info_silent_don.json\"), \"r\") as f_docs_info:\n",
    "    docs_info = json.load(f_docs_info)\n",
    "    authors = docs_info[\"authors\"]\n",
    "    file_names = docs_info[\"file_name\"]\n",
    "    for i, file_name in enumerate(tqdm(file_names)):\n",
    "        author = authors[i]\n",
    "        doc = compress_pickle.load(os.path.join(DATA_PATH, \"Обработанные ТД\", file_name))\n",
    "\n",
    "        features = get_list_of_features(doc)\n",
    "        observation = features + [author]\n",
    "        observations.append(observation)\n",
    "\n",
    "df_features = pd.DataFrame(observations, columns = all_func + [\"targets\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:49:04.521803100Z",
     "start_time": "2023-07-23T13:48:51.253262300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df_features.to_csv('out.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T13:49:10.228421900Z",
     "start_time": "2023-07-23T13:49:10.207299900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_test\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependance_accuracy_from_data\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\ML\\utils\\models_quality.py:86\u001B[0m\n\u001B[0;32m     83\u001B[0m         size_of_train\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlen\u001B[39m(x_train))\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_test, accuracy_train, size_of_test, size_of_train\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28mprint\u001B[39m(dependance_accuracy_from_data(\u001B[43mdf\u001B[49m, ExtraTreesClassifier()))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.models_quality import cross_val\n",
    "from utils.models_quality import cross_val_test\n",
    "from utils.models_quality import dependance_accuracy_from_data\n",
    "df = pd.read_csv('first_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T12:13:57.119932700Z",
     "start_time": "2023-07-23T12:13:57.075909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cross_val(df, CatBoostClassifier())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
