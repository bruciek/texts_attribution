{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-23T03:51:47.378200800Z",
     "start_time": "2023-07-23T03:51:38.760205900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:48:36.856419500Z",
     "start_time": "2023-07-22T11:48:36.478202800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def dataset_target(dataset):\n",
    "    authors = list(set(dataset['authors']))\n",
    "    dict_authors = dict()\n",
    "    reverse_dict_authors = dict()\n",
    "    for index in range(len(authors)):\n",
    "        dict_authors[authors[index]] = index\n",
    "        reverse_dict_authors[index] = authors[index]\n",
    "    target = []\n",
    "    for author in dataset[\"authors\"]:\n",
    "        target += [dict_authors[author]]\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:48:36.856419500Z",
     "start_time": "2023-07-22T11:48:36.829282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from features.features_lemma_part_speech import get_feature_lemma_part_speech\n",
    "from features.features_with_word_count import get_feature_symbol\n",
    "from features.features_with_sentence_list import get_feature_sents\n",
    "from features.features_words import get_feature_word\n",
    "\n",
    "def get_list_of_features(doc):\n",
    "    features_symbol = get_feature_symbol(doc)\n",
    "    features_words = get_feature_word(doc)\n",
    "    features_sents = get_feature_sents(doc)\n",
    "    features_lemma_part_speech = get_feature_lemma_part_speech(doc)\n",
    "    list_of_features = features_sents + features_words + features_symbol + features_lemma_part_speech\n",
    "    return list_of_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:48:36.861289300Z",
     "start_time": "2023-07-22T11:48:36.856419500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from features.features_words import func_words\n",
    "from features.features_with_sentence_list import FUNC_LIST\n",
    "from features.features_with_word_count import func_chars\n",
    "from features.features_lemma_part_speech import func_lemma_part_speech\n",
    "from tqdm import tqdm\n",
    "all_func = FUNC_LIST + func_words + func_chars + func_lemma_part_speech"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:48:36.877298400Z",
     "start_time": "2023-07-22T11:48:36.863290400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/516 [00:09<04:29,  1.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, file_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(file_names)):\n\u001B[0;32m     13\u001B[0m     author \u001B[38;5;241m=\u001B[39m authors[i]\n\u001B[1;32m---> 14\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mcompress_pickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mОбработанные\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     features \u001B[38;5;241m=\u001B[39m get_list_of_features(doc)\n\u001B[0;32m     17\u001B[0m     observation \u001B[38;5;241m=\u001B[39m features \u001B[38;5;241m+\u001B[39m [author]\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv1\\lib\\site-packages\\compress_pickle\\compress_pickle.py:272\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, compression, pickler_method, pickler_kwargs, mode, set_default_extension, **kwargs)\u001B[0m\n\u001B[0;32m    270\u001B[0m     pickler_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 272\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43muncompress_and_unpickle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompresser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpickler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickler_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    278\u001B[0m     compresser\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\functools.py:875\u001B[0m, in \u001B[0;36msingledispatch.<locals>.wrapper\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfuncname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires at least \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    873\u001B[0m                     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1 positional argument\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv1\\lib\\site-packages\\compress_pickle\\io\\base.py:99\u001B[0m, in \u001B[0;36mdefault_uncompress_and_unpickle\u001B[1;34m(compresser, pickler, **kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;129m@uncompress_and_unpickle\u001B[39m\u001B[38;5;241m.\u001B[39mregister(BaseCompresser)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_uncompress_and_unpickle\u001B[39m(\n\u001B[0;32m     97\u001B[0m     compresser: BaseCompresser, pickler: BasePicklerIO, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m     98\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompresser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv1\\lib\\site-packages\\compress_pickle\\picklers\\pickle.py:45\u001B[0m, in \u001B[0;36mBuiltinPicklerIO.load\u001B[1;34m(self, stream, **kwargs)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m, stream: IO[\u001B[38;5;28mbytes\u001B[39m], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     31\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load a serialized binary representation of an object from a stream.\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;124;03m        The python object that was loaded.\u001B[39;00m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\gzip.py:308\u001B[0m, in \u001B[0;36mGzipFile.peek\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpeek\u001B[39m(\u001B[38;5;28mself\u001B[39m, n):\n\u001B[1;32m--> 308\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_not_closed\u001B[49m()\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m!=\u001B[39m READ:\n\u001B[0;32m    310\u001B[0m         \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import compress_pickle\n",
    "import os\n",
    "\n",
    "\n",
    "observations = []\n",
    "DATA_PATH = \"C:\\\\Users\\\\mashk\\\\PycharmProjects\\\\texts_attribution\\\\Данные\"\n",
    "with open(os.path.join(DATA_PATH, \"docs_info.json\"), \"r\") as f_docs_info:\n",
    "    docs_info = json.load(f_docs_info)\n",
    "    authors = docs_info[\"authors\"]\n",
    "    file_names = docs_info[\"file_name\"]\n",
    "    for i, file_name in enumerate(tqdm(file_names)):\n",
    "        author = authors[i]\n",
    "        doc = compress_pickle.load(os.path.join(DATA_PATH, \"Обработанные\", file_name))\n",
    "\n",
    "        features = get_list_of_features(doc)\n",
    "        observation = features + [author]\n",
    "        observations.append(observation)\n",
    "\n",
    "df_features = pd.DataFrame(observations, columns = all_func + [\"target\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T11:48:46.585710400Z",
     "start_time": "2023-07-22T11:48:36.877298400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_features.to_csv('out.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_test\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels_quality\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependance_accuracy_from_data\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\ML\\utils\\models_quality.py:86\u001B[0m\n\u001B[0;32m     83\u001B[0m         size_of_train\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mlen\u001B[39m(x_train))\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_test, accuracy_train, size_of_test, size_of_train\n\u001B[1;32m---> 86\u001B[0m \u001B[38;5;28mprint\u001B[39m(dependance_accuracy_from_data(\u001B[43mdf\u001B[49m, ExtraTreesClassifier()))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from utils.models_quality import cross_val\n",
    "from utils.models_quality import cross_val_test\n",
    "from utils.models_quality import dependance_accuracy_from_data\n",
    "df = pd.read_csv('first_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T04:18:19.255096400Z",
     "start_time": "2023-07-23T04:18:19.191577400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcatboost\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CatBoostClassifier\n\u001B[1;32m----> 3\u001B[0m \u001B[43mcross_val\u001B[49m(df, CatBoostClassifier())\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cross_val' is not defined"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cross_val(df, CatBoostClassifier())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T04:18:03.359038400Z",
     "start_time": "2023-07-23T04:18:02.446266Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
