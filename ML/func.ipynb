{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.150648Z",
     "start_time": "2023-07-21T06:06:52.141695800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mean\n",
    "from feature_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.664968800Z",
     "start_time": "2023-07-21T06:06:52.146648600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_feature(dataset, func):\n",
    "    feature = [frequency_of_i, frequency_of_comma, frequency_of_dot, frequency_of_exclamation_mark, frequency_of_question_mark, frequency_of_brackets, frequency_of_quotation_marks, frequency_of_numbers, number_of_unique_words, number_of_words_that_occur_once, frequency_of_longest_word, average_lenght_of_sentence_by_letters, frequency_of_words_in_initial_form, correlation_of_vowels_consonants, most_common_first_letter_in_words, most_common_first_letter_in_sents, frequency_of_a, frequency_of_o, frequency_of_ะต, frequency_of_n, frequency_of_t, average_length_of_help_words, len_of_most_common_word, average_lenght_of_nouns, average_lenght_of_adjectives, average_lenght_of_adverbs, average_lenght_of_verbs, correlation_of_short_long_words, correlation_of_long_medium_words, semicolon_freq, count_upper_words, freq_of_freq_word, freq_word_from_adjective, freq_word_from_noun, freq_word_from_verbs, freq_of_space, sentences_avg_len_symbols, capitalized_words_count_without_start_of_sentences, avg_syllable_per_noun, avg_syllable_per_verb, avg_syllable_per_adjective, avg_syllable_per_adverb, count_words_infinitive]\n",
    "    for book in dataset['books']:\n",
    "        f = func(book)\n",
    "        feature.append(f)\n",
    "    return feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.681683700Z",
     "start_time": "2023-07-21T06:06:52.668971400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def dataset_target(dataset):\n",
    "    authors = list(set(dataset['authors']))\n",
    "    dict_authors = dict()\n",
    "    reverse_dict_authors = dict()\n",
    "    for index in range(len(authors)):\n",
    "        dict_authors[authors[index]] = index\n",
    "        reverse_dict_authors[index] = authors[index]\n",
    "    target = []\n",
    "    for author in dataset[\"authors\"]:\n",
    "        target += [dict_authors[author]]\n",
    "    return target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.699202300Z",
     "start_time": "2023-07-21T06:06:52.684656200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "target = dataset_target(dataset)\n",
    "dataset_for_ml = {\"targets\": target}\n",
    "df = pd.DataFrame(dataset_for_ml)\n",
    "\n",
    "functions = []\n",
    "for func in functions:\n",
    "    feature = get_feature(dataset, func)\n",
    "    df[func.__name__] = feature\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.712665300Z",
     "start_time": "2023-07-21T06:06:52.698203500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df.to_csv('out.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.730805400Z",
     "start_time": "2023-07-21T06:06:52.714664100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m         accuracy\u001B[38;5;241m.\u001B[39mappend(accuracy_score(y_test, rfc\u001B[38;5;241m.\u001B[39mpredict(x_test)))\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m accuracy\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28mprint\u001B[39m( mean(\u001B[43mvalidation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mExtraTreesClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m))\n",
      "Cell \u001B[1;32mIn[21], line 18\u001B[0m, in \u001B[0;36mvalidation\u001B[1;34m(df, model)\u001B[0m\n\u001B[0;32m     15\u001B[0m     x_train \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39miloc[train_ixs]\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtargets\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     17\u001B[0m     rfc \u001B[38;5;241m=\u001B[39m model\n\u001B[1;32m---> 18\u001B[0m     \u001B[43mrfc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     accuracy\u001B[38;5;241m.\u001B[39mappend(accuracy_score(y_test, rfc\u001B[38;5;241m.\u001B[39mpredict(x_test)))\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv_3.8\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv_3.8\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 348\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    352\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv_3.8\\lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv_3.8\\lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m     )\n\u001B[1;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1165\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\PycharmProjects\\texts_attribution\\venv_3.8\\lib\\site-packages\\sklearn\\utils\\validation.py:797\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    793\u001B[0m pandas_requires_conversion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    794\u001B[0m     _pandas_dtype_needs_early_conversion(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m dtypes_orig\n\u001B[0;32m    795\u001B[0m )\n\u001B[0;32m    796\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(dtype_iter, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;28;01mfor\u001B[39;00m dtype_iter \u001B[38;5;129;01min\u001B[39;00m dtypes_orig):\n\u001B[1;32m--> 797\u001B[0m     dtype_orig \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdtypes_orig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pandas_requires_conversion \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(d \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m dtypes_orig):\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;66;03m# Force object if any of the dtypes is an object\u001B[39;00m\n\u001B[0;32m    800\u001B[0m     dtype_orig \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mobject\u001B[39m\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mresult_type\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "def validation(df, model):\n",
    "    accuracy = []\n",
    "    for shift in range(0, 10, 2):\n",
    "        authors_seen = []\n",
    "        test_ixs = []\n",
    "        for ixs in range(len(df)):\n",
    "            aut = df['targets'][ixs]\n",
    "            if authors_seen.count(aut) < 2:\n",
    "                authors_seen += [aut]\n",
    "                test_ixs += [ixs + shift]\n",
    "        train_ixs = list(set(range(len(df))) - set(test_ixs))\n",
    "        y_test = df.iloc[test_ixs]['targets']\n",
    "        x_test = df.iloc[test_ixs].drop(columns=[\"targets\"])\n",
    "        y_train = df.iloc[train_ixs]['targets']\n",
    "        x_train = df.iloc[train_ixs].drop(columns=[\"targets\"])\n",
    "\n",
    "        rfc = model\n",
    "        rfc.fit(x_train, y_train)\n",
    "        accuracy.append(accuracy_score(y_test, rfc.predict(x_test)))\n",
    "    return accuracy\n",
    "\n",
    "print( mean(validation(df, ExtraTreesClassifier())))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T06:06:52.808032400Z",
     "start_time": "2023-07-21T06:06:52.730805400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "validation(df, CatBoostClassifier())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-21T06:06:52.806039500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
